  The goal is to enable saving the current VRM pose as a .vrma file. We've already set up the IPC communication between the renderer and main
  processes. Now, we need to implement the logic in the renderer process (src/renderer.ts) to:

   1. Capture the current pose of the currentVrm.
   2. Convert this pose into a VRMAnimation object.
   3. Export this VRMAnimation object into a GLTF format that includes the VRMC_vrm_animation extension.
   4. Send this GLTF data (as a string) to the main process via the saveVrmaPose IPC channel.

  Here are the changes for src/renderer.ts:

  First, add the `saveVrmaPoseToFile` function. You can place this function anywhere outside the loader.load callback, for example, right before
  logVrmBoneNames function.

   ... first 52 lines hidden ...
    53           if (boneData.position && boneName === VRMHumanBoneName.Hips) {
    54             result.extensions.VRMC_vrm_animation.humanoid.humanBones[boneName as VRMHumanBoneName].position = boneData.position.toArray();
    55           }
    56         });
    57 
    58         resolve(result);
    59       },
    60       (error) => {
    61         console.error('Error exporting GLTF:', error);
    62         resolve(null);
    63       },
    64       {
    65         // Options for GLTFExporter
    66         // We need to ensure the VRMC_vrm_animation extension is included
    67         extensions: {
    68           VRMC_vrm_animation: true,
    69         },
    70         // Embed everything in a single GLB file
    71         binary: true,
    72       }
    73     );
    74   });
    75 
    76   if (!gltfJson) {
    77     return { success: false, message: 'Failed to export GLTF data.' };
    78   }
    79 
    80   // Convert ArrayBuffer to a string for IPC (or handle as ArrayBuffer if IPC supports it)
    81   // For simplicity, we'll convert to a base64 string.
    82   // Note: This might be inefficient for large files.
    83   const vrmaData = JSON.stringify(gltfJson); // GLTFExporter with binary: true returns ArrayBuffer, so this needs adjustment.
    84 
    85   // If binary: true, exporter.parse returns an ArrayBuffer.
    86   // We need to convert it to a format suitable for IPC.
    87   // For now, let's assume we get a JSON object and stringify it.
    88   // If you need to save a binary .vrma, you'll need to send ArrayBuffer via IPC.
    89   // For this example, let's assume we are saving a JSON representation of the VRMA.
    90   // If `binary: true` is used, `exporter.parse` will return an `ArrayBuffer`.
    91   // You would then need to convert that `ArrayBuffer` to a `Buffer` in the main process
    92   // and write it to a file. For now, let's simplify and assume JSON export.
    93 
    94   // Let's re-evaluate the GLTFExporter usage for VRMA.
    95   // The `three-vrm-animation` library provides `createVRMAnimationHumanoidTracks`
    96   // which creates keyframe tracks. We need to create a full GLTF with these tracks.
    97   // This is more complex than just exporting the scene.
    98 
    99   // A simpler approach for saving the pose as VRMA:
   100   // 1. Get the current pose.
   101   // 2. Construct a minimal GLTF JSON that represents a VRMA file.
   102   //    This GLTF will contain the VRMC_vrm_animation extension with the pose data.
   103   // 3. Stringify the GLTF JSON.
   104 
   105   const vrmaGltf = {
   106     asset: {
   107       version: "2.0",
   108       generator: "AI-GF MVP VRMA Exporter",
   109     },
   110     extensionsUsed: ["VRMC_vrm_animation"],
   111     extensions: {
   112       VRMC_vrm_animation: {
   113         specVersion: "1.0",
   114         humanoid: {
   115           humanBones: {},
   116         },
   117       },
   118     },
   119     scenes: [
   120       {
   121         nodes: [],
   122       },
   123     ],
   124     nodes: [],
   125     animations: [
   126       {
   127         name: "Current Pose",
   128         channels: [],
   129         samplers: [],
   130       },
   131     ],
   132   };
   133 
   134   // Populate the VRMC_vrm_animation extension with the pose data
   135   Object.entries(currentPose).forEach(([boneName, boneData]) => {
   136     if (boneData.rotation) {
   137       vrmaGltf.extensions.VRMC_vrm_animation.humanoid.humanBones[boneName as VRMHumanBoneName] = {
   138         rotation: boneData.rotation.toArray(),
   139       };
   140     }
   141     if (boneData.position && boneName === VRMHumanBoneName.Hips) {
   142       vrmaGltf.extensions.VRMC_vrm_animation.humanoid.humanBones[boneName as VRMHumanBoneName].position = boneData.position.toArray();
   143     }
   144   });
   145 
   146   const vrmaDataString = JSON.stringify(vrmaGltf, null, 2); // Pretty print JSON
   147 
   148   // 4. Send the data to the main process
   149   const response = await (window as any).electronAPI.saveVrmaPose(vrmaDataString);
   150   return response;
   151 }

  Second, modify the `savePoseButton.onclick` handler. Find this block in src/renderer.ts:

    1       if (savePoseButton) {
    2         savePoseButton.onclick = () => {
    3           if (window.saveVrmPose) {
    4             savedPose = window.saveVrmPose();
    5             if (savedPose) {
    6               localStorage.setItem('vrmSavedPose', JSON.stringify(savedPose));
    7               console.log('Pose saved to localStorage.');
    8             }
    9           } else {
   10             console.warn('saveVrmPose function not available.');
   11           }
   12         };
   13       }

  And replace it with:

    1       if (savePoseButton) {
    2         savePoseButton.onclick = async () => {
    3           if (currentVrm) {
    4             const result = await saveVrmaPoseToFile(currentVrm);
    5             if (result.success) {
    6               console.log(result.message);
    7             } else {
    8               console.error(result.message);
    9             }
   10           } else {
   11             console.warn('currentVrm not available. Cannot save pose.');
   12           }
   13         };
   14       }

  Explanation of `saveVrmaPoseToFile`:

   * It takes the currentVrm as input.
   * It gets the current pose data using vrm.humanoid.getNormalizedPose().
   * It constructs a minimal GLTF JSON object (vrmaGltf) that includes the VRMC_vrm_animation extension. This extension is where the VRMA pose data is
     stored within a GLTF file.
   * It populates the humanBones section of the VRMC_vrm_animation extension with the rotation (and hips position) data from the current pose.
   * Finally, it stringifies this GLTF JSON and sends it to the main process via window.electronAPI.saveVrmaPose.

  After you apply these changes, rebuild and run your Electron application. 